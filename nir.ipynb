{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def comp_classification_loss(y_true, y_pred):\n",
    "    return -1/num_classes * tf.reduce_sum(y_true * tf.math.log(y_pred + 1e-9) + (1 - y_true) * tf.math.log(1 - y_pred + 1e-9))\n",
    "\n",
    "@tf.function\n",
    "def comp_regression_loss(y_true, y_pred):\n",
    "    return 1/num_classes * tf.reduce_sum(tf.square(y_true - y_pred))\n",
    "\n",
    "@tf.function\n",
    "def custom_loss(y_true, y_pred):\n",
    "    # Разделяем y_pred на части для классификации (y_pred_classification) и регрессии (y_pred_regression)\n",
    "    y_pred = [y_pred[0], y_pred[1]]\n",
    "    y_pred = tf.keras.layers.Concatenate()(y_pred)\n",
    "    y_pred_classification, y_pred_regression = tf.split(y_pred, num_or_size_splits=2, axis=-1)\n",
    "\n",
    "\n",
    "    y_true = [y_true[0], y_true[1]]\n",
    "    y_true = tf.keras.layers.Concatenate()(y_true)\n",
    "    # Разделяем y_true на части для классификации (y_true_classification) и регрессии (y_true_regression)\n",
    "    y_true_classification, y_true_regression = tf.split(y_true, num_or_size_splits=2, axis=-1)\n",
    "\n",
    "    # Компонент функции потерь для классификации (бинарная кросс-энтропия)\n",
    "    # classification_loss = -1/num_classes * tf.reduce_sum(y_true_classification * tf.math.log(y_pred_classification + 1e-9) + (1 - y_true_classification) * tf.math.log(1 - y_pred_classification + 1e-9))\n",
    "\n",
    "    # Компонент функции потерь для регрессии (среднеквадратичная ошибка)\n",
    "    # regression_loss = 1/num_classes * tf.reduce_sum(tf.square(y_true_regression - y_pred_regression))\n",
    "\n",
    "    # Общая функция потерь\n",
    "    total_loss = -1/num_classes * tf.reduce_sum(y_true_classification * tf.math.log(y_pred_classification + 1e-9) + (1 - y_true_classification) * tf.math.log(1 - y_pred_classification + 1e-9)) + 1/num_classes * tf.reduce_sum(tf.square(y_true_regression - y_pred_regression))\n",
    "\n",
    "    return total_loss\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T18:29:14.664862400Z",
     "start_time": "2023-11-13T18:29:11.089405400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-13T19:00:11.935788700Z",
     "start_time": "2023-11-13T18:29:14.680448100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 589 images belonging to 3 classes.\n",
      "13/13 [==============================] - 1851s 145s/step - loss: nan - dense_loss: 0.8249 - dense_1_loss: nan - dense_comp_classification_loss: 19.5932 - dense_comp_regression_loss: 6.8055 - dense_1_comp_classification_loss: nan - dense_1_comp_regression_loss: 16.5084 - val_loss: nan - val_dense_loss: 1.0995 - val_dense_1_loss: nan - val_dense_comp_classification_loss: 18.8436 - val_dense_comp_regression_loss: 6.6001 - val_dense_1_comp_classification_loss: nan - val_dense_1_comp_regression_loss: 30.2609\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "import os\n",
    "import cv2\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import Xception\n",
    "from keras.layers import Conv2D, Dense\n",
    "from keras.models import Model\n",
    "import xml.etree.ElementTree as ET\n",
    "from keras.utils import to_categorical, serialize_keras_object\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "annotations_dir = 'annotation'\n",
    "annotations = {}\n",
    "\n",
    "# Функция для масштабирования координат в аннотациях\n",
    "def scale_bbox(xmin, ymin, xmax, ymax, width_scale, height_scale):\n",
    "    xmin_scaled = int(xmin * width_scale)\n",
    "    ymin_scaled = int(ymin * height_scale)\n",
    "    xmax_scaled = int(xmax * width_scale)\n",
    "    ymax_scaled = int(ymax * height_scale)\n",
    "    return xmin_scaled, ymin_scaled, xmax_scaled, ymax_scaled\n",
    "\n",
    "# Создаем генератор данных для предобработки изображений\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255.0,\n",
    "    validation_split=0.3  # Разделение данных на обучающий и валидационный наборы\n",
    ")\n",
    "\n",
    "for breed_folder in os.listdir(annotations_dir):\n",
    "    if os.path.isdir(os.path.join(annotations_dir, breed_folder)):\n",
    "        breed_annotations = {}\n",
    "        for annotation_file in os.listdir(os.path.join(annotations_dir, breed_folder)):\n",
    "            tree = ET.parse(os.path.join(annotations_dir, breed_folder, annotation_file))\n",
    "            root = tree.getroot()\n",
    "            class_name = root.find('object').find('name').text\n",
    "\n",
    "            bndbox = root.find('object').find('bndbox')\n",
    "            xmin = int(bndbox.find('xmin').text)\n",
    "            ymin = int(bndbox.find('ymin').text)\n",
    "            xmax = int(bndbox.find('xmax').text)\n",
    "            ymax = int(bndbox.find('ymax').text)\n",
    "\n",
    "            # Путь к соответствующему изображению\n",
    "            image_filename = os.path.splitext(annotation_file)[0]\n",
    "            image_path = os.path.join('images', breed_folder, image_filename) + '.jpg'\n",
    "\n",
    "            # Загружаем изображение и получаем его размер\n",
    "            img = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "            original_image_height, original_image_width, _ = img.shape\n",
    "\n",
    "            # Рассчитываем коэффициенты масштабирования\n",
    "            width_scale = 448 / original_image_width\n",
    "            height_scale = 448 / original_image_height\n",
    "\n",
    "            # Масштабируем координаты в аннотациях\n",
    "            xmin, ymin, xmax, ymax = scale_bbox(xmin, ymin, xmax, ymax, width_scale, height_scale)\n",
    "\n",
    "            breed_annotations[image_filename] = {'class_name': class_name, 'bbox': (xmin, ymin, xmax, ymax)}\n",
    "\n",
    "        annotations[breed_folder] = breed_annotations\n",
    "\n",
    "image_dir = 'images'\n",
    "\n",
    "# Преобразование изображений с использованием генератора данных\n",
    "batch_size = 32\n",
    "generator = datagen.flow_from_directory(\n",
    "    image_dir,\n",
    "    target_size=(448, 448),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    color_mode='grayscale'\n",
    ")\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "for _ in range(len(generator)):\n",
    "    batch_images, batch_labels = generator.next()\n",
    "    images.extend(batch_images)\n",
    "    labels.extend(batch_labels)\n",
    "\n",
    "# Преобразование меток в числовой формат (категориальное кодирование)\n",
    "unique_labels = list(generator.class_indices.keys())\n",
    "num_classes = len(unique_labels)\n",
    "label_to_id = {label: i for i, label in enumerate(unique_labels)}\n",
    "labels = [np.argmax(label) for label in labels]\n",
    "labels = to_categorical(labels, num_classes=num_classes)\n",
    "images = np.array(images)\n",
    "\n",
    "\n",
    "# Загрузка предварительно обученной модели Xception\n",
    "base_model = Xception(weights='imagenet', include_top=False)\n",
    "\n",
    "# Входной тензор для одноканального изображения\n",
    "input_image = tf.keras.Input(shape=(448, 448, 1))\n",
    "\n",
    "\n",
    "pseudo_rgb_image = Conv2D(3, (1, 1))(input_image)\n",
    "\n",
    "x = base_model(pseudo_rgb_image)\n",
    "cam_x = base_model.get_layer('block13_sepconv2_act')(x)\n",
    "x = GlobalAveragePooling2D()(cam_x)\n",
    "old_weights = base_model.get_weights()\n",
    "\n",
    "# 2xDense\n",
    "classification = Dense(num_classes, activation='sigmoid')(x)\n",
    "regression = Dense(num_classes, activation='linear')(x)\n",
    "\n",
    "model = Model(inputs=input_image, outputs=[classification, regression])\n",
    "\n",
    "# model.save('model_structure.h5', include_optimizer=False)\n",
    "\n",
    "\n",
    "# Компилирование модели\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss=custom_loss, metrics=[comp_classification_loss, comp_regression_loss])\n",
    "model.fit(images, [labels, labels], batch_size=32, epochs=1, validation_split=0.3)\n",
    "\n",
    "classification_config = serialize_keras_object(model.layers[-2])\n",
    "classification_config_json = json.dumps(classification_config)\n",
    "\n",
    "with open(\"classification_layer_structure.json\", \"w\") as json_file:\n",
    "    json_file.write(classification_config_json)\n",
    "classification_layer_weights = model.layers[-2].get_weights()\n",
    "regression_layer_weights = model.layers[-1].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "np.save('classification_weights_1.npy', classification_layer_weights[0])\n",
    "np.save('classification_weights_2.npy', classification_layer_weights[1])\n",
    "\n",
    "np.save('regression_weights_1.npy', regression_layer_weights[0])\n",
    "np.save('regression_weights_2.npy', regression_layer_weights[1])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T19:01:14.672561200Z",
     "start_time": "2023-11-13T19:01:14.610048600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "def preprocess_image(image_path, target_size=(448, 448)):\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, target_size)\n",
    "    img = img / 255.0\n",
    "    img = np.expand_dims(img, axis=-1)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "\n",
    "    return img"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T19:04:19.310300200Z",
     "start_time": "2023-11-13T19:04:19.297334300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00272024 -0.00819132 -0.00259256]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "regression_layer_weights = [np.load('regression_weights_1.npy'), np.load('regression_weights_2.npy')]\n",
    "classification_layer_weights = [np.load('classification_weights_1.npy'), np.load('classification_weights_2.npy')]\n",
    "print(classification_layer_weights[1])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T07:18:23.203777100Z",
     "start_time": "2023-11-14T07:18:23.175697800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.models import load_model\n",
    "from keras.layers import BatchNormalization\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "regression_layer_weights = [np.load('regression_weights_1.npy'), np.load('regression_weights_2.npy')]\n",
    "classification_layer_weights = [np.load('classification_weights_1.npy'), np.load('classification_weights_2.npy')]\n",
    "\n",
    "# loaded_model = load_model('model_structure.h5',custom_objects={'BatchNormalization': BatchNormalization}, compile=False)\n",
    "image = preprocess_image(\"images/n02085936-Maltese_dog/n02085936_233.jpg\")\n",
    "# plt.imshow(image)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T19:10:10.500984700Z",
     "start_time": "2023-11-13T19:10:10.477253300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown layer: {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 3, \"activation\": \"sigmoid\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}. Please ensure this object is passed to the `custom_objects` argument. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[26], line 12\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mclassification_layer_structure.json\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m json_file:\n\u001B[0;32m     10\u001B[0m     loaded_classification_config_json \u001B[38;5;241m=\u001B[39m json_file\u001B[38;5;241m.\u001B[39mread()\n\u001B[1;32m---> 12\u001B[0m loaded_classification_layer \u001B[38;5;241m=\u001B[39m \u001B[43mdeserialize\u001B[49m\u001B[43m(\u001B[49m\u001B[43mloaded_classification_config_json\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     15\u001B[0m transformed_model \u001B[38;5;241m=\u001B[39m Model(inputs\u001B[38;5;241m=\u001B[39minput_image, outputs\u001B[38;5;241m=\u001B[39mloaded_classification_layer)\n\u001B[0;32m     17\u001B[0m layer_output \u001B[38;5;241m=\u001B[39m transformed_model\u001B[38;5;241m.\u001B[39mpredict(image)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\nir_project\\lib\\site-packages\\keras\\layers\\serialization.py:249\u001B[0m, in \u001B[0;36mdeserialize\u001B[1;34m(config, custom_objects)\u001B[0m\n\u001B[0;32m    212\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Instantiates a layer from a config dictionary.\u001B[39;00m\n\u001B[0;32m    213\u001B[0m \n\u001B[0;32m    214\u001B[0m \u001B[38;5;124;03mArgs:\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    246\u001B[0m \u001B[38;5;124;03m```\u001B[39;00m\n\u001B[0;32m    247\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    248\u001B[0m populate_deserializable_objects()\n\u001B[1;32m--> 249\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mgeneric_utils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdeserialize_keras_object\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    250\u001B[0m \u001B[43m    \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    251\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodule_objects\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mLOCAL\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mALL_OBJECTS\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    252\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcustom_objects\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcustom_objects\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    253\u001B[0m \u001B[43m    \u001B[49m\u001B[43mprintable_module_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mlayer\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    254\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\nir_project\\lib\\site-packages\\keras\\utils\\generic_utils.py:769\u001B[0m, in \u001B[0;36mdeserialize_keras_object\u001B[1;34m(identifier, module_objects, custom_objects, printable_module_name)\u001B[0m\n\u001B[0;32m    767\u001B[0m     obj \u001B[38;5;241m=\u001B[39m module_objects\u001B[38;5;241m.\u001B[39mget(object_name)\n\u001B[0;32m    768\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m obj \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 769\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    770\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnknown \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mprintable_module_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mobject_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. Please \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    771\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mensure this object is passed to the `custom_objects` \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    772\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124margument. See \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    773\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttps://www.tensorflow.org/guide/keras/save_and_serialize\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    774\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m#registering_the_custom_object for details.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    775\u001B[0m         )\n\u001B[0;32m    777\u001B[0m \u001B[38;5;66;03m# Classes passed by name are instantiated with no args, functions are\u001B[39;00m\n\u001B[0;32m    778\u001B[0m \u001B[38;5;66;03m# returned as-is.\u001B[39;00m\n\u001B[0;32m    779\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m tf_inspect\u001B[38;5;241m.\u001B[39misclass(obj):\n",
      "\u001B[1;31mValueError\u001B[0m: Unknown layer: {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 3, \"activation\": \"sigmoid\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}. Please ensure this object is passed to the `custom_objects` argument. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details."
     ]
    }
   ],
   "source": [
    "from keras import Model\n",
    "from keras.layers import Dense, deserialize\n",
    "from keras.models import model_from_config, model_from_json\n",
    "import tensorflow as tf\n",
    "import json\n",
    "\n",
    "input_image = tf.keras.Input(shape=(448, 448, 1))\n",
    "\n",
    "with open(\"classification_layer_structure.json\", \"r\") as json_file:\n",
    "    loaded_classification_config_json = json_file.read()\n",
    "\n",
    "loaded_classification_layer = deserialize(loaded_classification_config_json)\n",
    "\n",
    "\n",
    "transformed_model = Model(inputs=input_image, outputs=loaded_classification_layer)\n",
    "\n",
    "layer_output = transformed_model.predict(image)\n",
    "\n",
    "# ram_image = np.dot(layer_output, regression_layer_weights)\n",
    "# ram_image = np.squeeze(ram_image)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T19:35:21.608856300Z",
     "start_time": "2023-11-13T19:35:21.548022Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No such layer: block5_sepconv2_act. Existing layers are: ['input_2', 'conv2d_4', 'xception', 'block13_sepconv2_act', 'global_average_pooling2d', 'dense', 'dense_1'].",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[11], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m block5_output \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_layer\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mblock5_sepconv2_act\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39moutput\n\u001B[0;32m      2\u001B[0m block7_output \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mget_layer(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mblock7_sepconv2_act\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;241m.\u001B[39moutput\n\u001B[0;32m      3\u001B[0m block9_output \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mget_layer(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mblock9_sepconv2_act\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;241m.\u001B[39moutput\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\NIR\\lib\\site-packages\\keras\\engine\\training.py:3275\u001B[0m, in \u001B[0;36mModel.get_layer\u001B[1;34m(self, name, index)\u001B[0m\n\u001B[0;32m   3273\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m layer\u001B[38;5;241m.\u001B[39mname \u001B[38;5;241m==\u001B[39m name:\n\u001B[0;32m   3274\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m layer\n\u001B[1;32m-> 3275\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   3276\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo such layer: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. Existing layers are: \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   3277\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlist\u001B[39m(layer\u001B[38;5;241m.\u001B[39mname\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mfor\u001B[39;00m\u001B[38;5;250m \u001B[39mlayer\u001B[38;5;250m \u001B[39m\u001B[38;5;129;01min\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayers)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   3278\u001B[0m     )\n\u001B[0;32m   3279\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   3280\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mProvide either a layer name or layer index at \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`get_layer`.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   3281\u001B[0m )\n",
      "\u001B[1;31mValueError\u001B[0m: No such layer: block5_sepconv2_act. Existing layers are: ['input_2', 'conv2d_4', 'xception', 'block13_sepconv2_act', 'global_average_pooling2d', 'dense', 'dense_1']."
     ]
    }
   ],
   "source": [
    "block5_output = model.get_layer('block5_sepconv2_act').output\n",
    "block7_output = model.get_layer('block7_sepconv2_act').output\n",
    "block9_output = model.get_layer('block9_sepconv2_act').output\n",
    "block11_output = model.get_layer('block11_sepconv2_act').output\n",
    "\n",
    "GAP_after_block5 = GlobalAveragePooling2D()(block5_output)\n",
    "GAP_after_block7 = GlobalAveragePooling2D()(block7_output)\n",
    "GAP_after_block9 = GlobalAveragePooling2D()(block9_output)\n",
    "GAP_after_block11 = GlobalAveragePooling2D()(block11_output)\n",
    "\n",
    "# block13_output = model.get_layer('block13_sepconv2_act').output\n",
    "\n",
    "model_with_GAP = Model(inputs=model.input, outputs=[block5_output, GAP_after_block5, block7_output, GAP_after_block7, block9_output, GAP_after_block9, block11_output, GAP_after_block11])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T13:58:56.805477200Z",
     "start_time": "2023-11-08T13:58:56.356240900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
